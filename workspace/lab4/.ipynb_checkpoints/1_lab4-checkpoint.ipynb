{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df7908a5",
   "metadata": {},
   "source": [
    "# Lab 4: Sparse Matrix Multiplication and Hardware Optimization\n",
    "\n",
    "In this lab, we will explore opportunities for optimizing sparse matrix multiplication in hardware. We'll examine different optimization techniques like gating and skipping, and understand their impact on latency and energy efficiency. The lab will cover:\n",
    "\n",
    "- Dense vs sparse matrix multiplication\n",
    "- Optimization opportunities in sparse computations\n",
    "- Hardware techniques for handling sparsity\n",
    "- Energy and latency trade-offs of different techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b66334",
   "metadata": {},
   "source": [
    "#### Question 1.0\n",
    "Please answer the following questions. Otherwise, your submission will not be graded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3e756e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loaders import *\n",
    "\n",
    "answer(\n",
    "    question='1.0',\n",
    "    subquestion=f'What is your name?',\n",
    "    answer= 'Khushi Parikh',\n",
    "    required_type=str,\n",
    ")\n",
    "answer(\n",
    "    question='1.0',\n",
    "    subquestion=f'What is your email address?',\n",
    "    answer= 'khushi25@mit.edu',\n",
    "    required_type=str,\n",
    ")\n",
    "answer(\n",
    "    question='1.0',\n",
    "    subquestion=f'What is your kerberos?',\n",
    "    answer= 'khushi25',\n",
    "    required_type=str,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb31bdf1",
   "metadata": {},
   "source": [
    "# Part 1: Sparse Optimization Opportunities in Matrix Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acddd9e7",
   "metadata": {},
   "source": [
    "Matrix multiplication is a fundamental operation in many computing applications, especially in machine learning and scientific computing. However, when matrices are sparse (containing many zeros), performing dense matrix multiplication can be inefficient, wasting both time and energy on operations involving zeros.\n",
    "\n",
    "In this section, we will:\n",
    "1. Review dense matrix multiplication as a baseline\n",
    "2. Explore how sparsity creates opportunities for optimization\n",
    "3. Analyze two key optimization techniques: gating and skipping\n",
    "4. Calculate the potential savings in computation and energy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dc73c8",
   "metadata": {},
   "source": [
    "In all following questions, please assume that all tensors are independently\n",
    "distributed (*e.g.*, if the density of A is 0.3 and the density of B is 0.4,\n",
    "then you can assume that a multiplication in any tensor operation between A and\n",
    "B has a $0.3 \\times 0.4$ chance of being nonzero.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f48d042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loaders import *\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy.sparse as ss\n",
    "%run ./prelude.py --style=uncompressed --animation=movie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e0df09",
   "metadata": {},
   "source": [
    "## Dense Matrix Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0284fa4d",
   "metadata": {},
   "source": [
    "Before we discuss sparse matrix multiplication, we'll recap dense matrix multiplication. In the animation below, we'll see a simple animation of the matrix multiplication\n",
    "\n",
    "$$Z_{m,n}=A_{m,k}B_{k,n}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f644d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set default problem instance attributes (i.e., the shape of the tensors)\n",
    "K = 4\n",
    "M = 3\n",
    "N = 3\n",
    "\n",
    "A_MK = Tensor.fromRandom(name='A', rank_ids=['M', 'K'], shape=[M, K], density=1.0, color='blue')\n",
    "B_KN = Tensor.fromRandom(name='B', rank_ids=['K', 'N'], shape=[K, N], density=1.0, color='green')\n",
    "Z_MN = Tensor(name='Z', rank_ids=[\"M\", \"N\"], shape=[M, N], color='red')\n",
    "\n",
    "canvas = createCanvas(A_MK, B_KN, Z_MN)\n",
    "cycle = 0\n",
    "\n",
    "A_m = A_MK.getRoot()\n",
    "B_k = B_KN.getRoot()\n",
    "Z_m = Z_MN.getRoot()\n",
    "\n",
    "# Traverse non-empty elements of top rank of `A`\n",
    "for m, (Z_m_ref, A_k) in Z_m << A_m:\n",
    "    # Traverse the K rank of `A`\n",
    "    for k, A_val in A_k:\n",
    "        # Obtain the matching fiber in `B`\n",
    "        B_n = B_k.getPayload(k)\n",
    "        # Traverse the bottom rank of `B`\n",
    "        for n, (Z_mn_ref, B_val) in Z_m_ref << B_n:\n",
    "            # Do the reduction\n",
    "            Z_mn_ref += A_val * B_val\n",
    "            # Animation bookkeeping\n",
    "            canvas.addActivity((m,k), (k,n), (m, n), spacetime=(0,cycle))\n",
    "            cycle += 1\n",
    "\n",
    "displayCanvas(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c567e720",
   "metadata": {},
   "source": [
    "## Sparse Optimization Opportunities\n",
    "\n",
    "Now, we'll see what happens if the tensor $A$ is sparse with density 0.5. **Note which part of the code below is changed**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9457c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set default problem instance attributes (i.e., the shape of the tensors)\n",
    "K = 4\n",
    "M = 3\n",
    "N = 3\n",
    "\n",
    "########################################\n",
    "### NOTE: density of A_MK is changed ###\n",
    "########################################\n",
    "A_MK = Tensor.fromRandom(name='A', rank_ids=['M', 'K'], shape=[M, K], density=0.5, color='blue')\n",
    "B_KN = Tensor.fromRandom(name='B', rank_ids=['K', 'N'], shape=[K, N], density=1.0, color='green')\n",
    "Z_MN = Tensor(name='Z', rank_ids=[\"M\", \"N\"], shape=[M, N], color='red')\n",
    "\n",
    "canvas = createCanvas(A_MK, B_KN, Z_MN)\n",
    "cycle = 0\n",
    "\n",
    "A_m = A_MK.getRoot()\n",
    "B_k = B_KN.getRoot()\n",
    "Z_m = Z_MN.getRoot()\n",
    "\n",
    "# Traverse non-empty elements of top rank of `A`\n",
    "for m, (Z_m_ref, A_k) in Z_m << A_m:\n",
    "    # Traverse the K rank of `A`\n",
    "    for k, A_val in A_k:\n",
    "        # Obtain the matching fiber in `B`\n",
    "        B_n = B_k.getPayload(k)\n",
    "        # Traverse the bottom rank of `B`\n",
    "        for n, (Z_mn_ref, B_val) in Z_m_ref << B_n:\n",
    "            # Do the reduction\n",
    "            Z_mn_ref += A_val * B_val\n",
    "            # Animation bookkeeping\n",
    "            canvas.addActivity((m,k), (k,n), (m, n), spacetime=(0,cycle))\n",
    "            cycle += 1\n",
    "\n",
    "displayCanvas(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daee667a",
   "metadata": {},
   "source": [
    "### Question 1.1-1.4\n",
    "Optimizing Ineffectual Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f3c699",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer(\n",
    "    question='1.1',\n",
    "    subquestion=f'What is the loop order of the dataflow illustrated above? Answer from outermost to innermost loop.',\n",
    "    answer= 'MKN',\n",
    "    required_type=('MKN', 'MNK', 'KMN', 'KNM', 'NKM', 'NMK')\n",
    ")\n",
    "answer(\n",
    "    question='1.2',\n",
    "    subquestion=f'If the density of the tensor A is 1, the density of tensor B is 1, and M=K=N=8, then how many effectual multiplies are there?',\n",
    "    answer= 512,\n",
    "    required_type=int\n",
    ")\n",
    "answer(\n",
    "    question='1.3',\n",
    "    subquestion=f'If the density of the tensor A is 0.5, the density of tensor B is 1, and M=K=N=8, then how many effectual (non-zero) multiplies are there?',\n",
    "    answer= 256,\n",
    "    required_type=int\n",
    ")\n",
    "answer(\n",
    "    question='1.3',\n",
    "    subquestion=f'If the density of the tensor A is 0.5, the density of tensor B is 1, and M=K=N=8, then how many ineffectual multiplies are there?',\n",
    "    answer= 256,\n",
    "    required_type=int\n",
    ")\n",
    "answer(\n",
    "    question='1.4',\n",
    "    subquestion=f'If the density of tensors A and B are both 0.5, and M=K=N=8, then how many effectual multiplies are there?',\n",
    "    answer= 128,\n",
    "    required_type=int\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4dfcc3",
   "metadata": {},
   "source": [
    "#### Question 1.5: \n",
    "There are two optimizations for ineffectual operations: gating and skipping. Gating explicitly lets the hardware staying idle on the ineffectual operation. Skipping explicitly fast forwards to next effectual operation. We provide you an example of cycle-behavior of each optimization in figure below for your understanding. Please specify the effect of each optimization in terms of latency and energy.\n",
    "![explain](figures/GateSkipExample.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214943d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gating: fewer operations (read, compute), same number of processing steps\n",
    "answer(\n",
    "    question='1.5',\n",
    "    subquestion=f'What might gating save in terms of latency, energy or both?',\n",
    "    answer= 'energy',\n",
    "    required_type=('latency', 'energy', 'both')\n",
    ")\n",
    "\n",
    "# skipping: fewer operations, fewer processing steps\n",
    "answer(\n",
    "    question='1.5',\n",
    "    subquestion=f'What might skipping save in terms of latency, energy or both?',\n",
    "    answer= 'both',\n",
    "    required_type=('latency', 'energy', 'both')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fb8c13",
   "metadata": {},
   "source": [
    "## Tiled Sparse Matrix Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bc0094",
   "metadata": {},
   "source": [
    "Suppose we want to tile the matrix multiplication in the $N$ rank into $N1$ and $N0$ and have the following loop nest.\n",
    "\n",
    "```\n",
    "for n1 in [0,N1)\n",
    " for m in [0,M)\n",
    "  for k in [0,K)\n",
    "   for n0 in [0,N0)\n",
    "```\n",
    "\n",
    "First, we tile the dimension $N$ into $N0$ and $N1$. This transforms tensor $B_{k,n}$ to $B_{k,n1,n0}$. The order of ranks of $B$ in memory is ```k -> n1 -> n0``` in $B_{k,n1,n0}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b09f62",
   "metadata": {},
   "source": [
    "#### Question 1.6\n",
    "Consider iterating through tensor $B_{k, n1, n0}$ in the order of the loop nest above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30ca67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "answer(\n",
    "    question='1.6',\n",
    "    subquestion=f'How would you describe the traversal of the $k$ rank in the order of the loop nest above if $B$ is compressed at the $k$ rank? (concordant, discordant)',\n",
    "    answer= 'discordant',\n",
    "    required_type=('concordant', 'discordant')\n",
    ")\n",
    "\n",
    "answer(\n",
    "    question='1.6',\n",
    "    subquestion=f'Would the above be more or less efficient than the traversal of the $k$ rank if it were compressed at the N0 rank? (more, less)',\n",
    "    answer= 'less',\n",
    "    required_type=('more', 'less')\n",
    ")\n",
    "\n",
    "answer(\n",
    "    question='1.6',\n",
    "    subquestion=f'Alternatively, would the first be more or less efficient than the traversal of the $k$ rank if it were compressed at the N1 rank? (more, less)',\n",
    "    answer= 'less',\n",
    "    required_type=('more', 'less')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82fa18c",
   "metadata": {},
   "source": [
    "You can observe how we leverage the above in the following images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97298fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 4\n",
    "M = 3\n",
    "N = 6\n",
    "N0 = 3\n",
    "\n",
    "# Note: B is now also sparse\n",
    "B_KN = Tensor.fromRandom(name='B', rank_ids=['K', 'N'], shape=[K, N], density=0.75, color='green')\n",
    "\n",
    "# NOTE: Split N rank in B\n",
    "B_KN1N0 = B_KN.splitUniform(N0, depth=1)\n",
    "displayTensor(B_KN)\n",
    "displayTensor(B_KN1N0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb522b7",
   "metadata": {},
   "source": [
    "You can see there is a lot of inefficiency in storing weights that are 0. Because of this inefficiency, we'll rearrange the ranks of $B$ into $B_{n_1,k,n_0}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19e26b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_N1KN0 = B_KN1N0.swapRanks()\n",
    "displayTensor(B_N1KN0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b645167",
   "metadata": {},
   "source": [
    "Now, we will show a matmul on the rearranged tensor $B$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed742fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_MN = Tensor(name='Z', rank_ids=[\"M\", \"N\"], shape=[M, N], color='red')\n",
    "Z_N1MN0 = Z_MN.splitUniform(N0, depth=1).swapRanks()\n",
    "\n",
    "canvas = createCanvas(A_MK, B_N1KN0, Z_N1MN0)\n",
    "cycle = 0\n",
    "\n",
    "A_m = A_MK.getRoot()\n",
    "B_n1 = B_N1KN0.getRoot()\n",
    "Z_n1 = Z_N1MN0.getRoot()\n",
    "\n",
    "# Traverse non-empty elements of top rank of `A`\n",
    "for n1, (Z_n1_ref, B_n1k) in Z_n1 << B_n1:\n",
    "    for m, (Z_n1m_ref, A_mk) in Z_n1_ref << A_m:\n",
    "        for k, A_val in A_mk:\n",
    "            B_n1kn0 = B_n1k.getPayload(k)\n",
    "            for n0, (Z_n1mn_ref, B_val) in Z_n1m_ref << B_n1kn0:\n",
    "                Z_n1mn_ref += A_val * B_val\n",
    "\n",
    "                # Animation bookkeeping\n",
    "                canvas.addActivity((m,k), (n1,k,n0), (n1, m, n0),\n",
    "                                   spacetime=(0,cycle))\n",
    "                cycle += 1\n",
    "\n",
    "displayCanvas(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9f2860",
   "metadata": {},
   "source": [
    "#### Question 1.7\n",
    "Note that the number of non-zeroes in each $B_{n_1}$ (a tile with dimensions $k$ and $n_0$) are smaller than $K \\cdot N_0$ because of sparsity. We may be able to use a smaller buffer to store the tiles if we compress them. \n",
    "\n",
    "*Please note: this video may exceed screen size limits.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b6396b",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer(\n",
    "    question='1.7',\n",
    "    subquestion=f'Compression can increase the total amount of stored data when sparsity is low (i.e., density is high). However, the additional data stored will never exceed the savings from omitting zero values. (True/False)',\n",
    "    answer= False,\n",
    "    required_type=bool\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb1e04b",
   "metadata": {},
   "source": [
    "# Part 2: Saving Energy with Gating\n",
    "\n",
    "In this section, we will explore how gating can be used with sparse matrix multiplication. We will experiment with sparse architectures with gating using Sparseloop (an extension of Timeloop to support sparse architectures).\n",
    "\n",
    "For this and part 3 (unless otherwise specified), we will look at a 2-level architecture with untiled mapping (see below).\n",
    "\n",
    "![gating setup](figures/gating.png)\n",
    "\n",
    "In the following cells, we show the problem, architecture, and mapping specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b02ae4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_config('designs/problem.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33b1262",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_config('designs/arch.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c149cdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_config('designs/untiled.map.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b57add",
   "metadata": {},
   "source": [
    "Below, we show the sparse optimization specification for Sparseloop. Note that both $A$ and $B$ in this scenario are **uncompressed**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb272ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_config('designs/sparse_opts/buffer_gating.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c9e611",
   "metadata": {},
   "source": [
    "We run Sparseloop without the sparse optimization first, then with the optimizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b46a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    " # The designs/top.yaml.jinja2 file includes designs/arch.yaml and designs/problem.yaml by default\n",
    "result = run_timeloop_model(\n",
    "    jinja_parse_data=dict(\n",
    "        mapping='designs/untiled.map.yaml'\n",
    "    )\n",
    ")\n",
    "stats = open('./output_dir/timeloop-model.stats.txt', 'r').read()\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e95f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    " # The designs/top.yaml.jinja2 file includes designs/arch.yaml and designs/problem.yaml by default\n",
    "result = run_timeloop_model(\n",
    "    jinja_parse_data=dict(\n",
    "        mapping='designs/untiled.map.yaml',\n",
    "        sparse_optimizations='designs/sparse_opts/buffer_gating.yaml'\n",
    "    )\n",
    ")\n",
    "stats = open('./output_dir/timeloop-model.stats.txt', 'r').read()\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e7e007",
   "metadata": {},
   "source": [
    "#### Question 2.1-2.2 \n",
    "The *algorithmic-compute* stat is the number of computes in the workload without considering sparsity, while the *compute* stat considers sparsity. \n",
    "Accordingly, the *compute* stat (actual computes) describes the effectual computations, while the *algorithmic-compute* stat describes the sum of \n",
    "both effectual computations and ineffectual computations. Note that, when we gate computes, we may decrease total energy while increasing fJ/compute. This is\n",
    "because we are decreasing the number of computes occurring.\n",
    "\n",
    "Please fill the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6268d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer(\n",
    "    question='2.1',\n",
    "    subquestion=f'What is the total fJ/Algorithmic-Compute compute without gating? If algorithmic-compute numbers are not available, use the total fJ/compute.',\n",
    "    answer= 7047.25,\n",
    "    required_type=Number\n",
    ")\n",
    "\n",
    "answer(\n",
    "    question='2.1',\n",
    "    subquestion=f'What is the total fJ/Algorithmic-Compute with gating? If algorithmic-compute numbers are not available, use the total fJ/compute.',\n",
    "    answer= 3972.35,\n",
    "    required_type=Number\n",
    ")\n",
    "\n",
    "answer(\n",
    "    question='2.1',\n",
    "    subquestion='Which storage element was gated?',\n",
    "    answer= 'Buffer',\n",
    "    required_type=('Buffer', 'DRAM', 'MAC'),\n",
    ")\n",
    "\n",
    "answer(\n",
    "    question='2.1',\n",
    "    subquestion='Which compute element was gated?',\n",
    "    answer= 'MAC',\n",
    "    required_type=('Buffer', 'DRAM', 'MAC'),\n",
    ")\n",
    "\n",
    "answer(\n",
    "    question='2.1',\n",
    "    subquestion='Gating did NOT change the energy of which component?',\n",
    "    answer= 'DRAM',\n",
    "    required_type=('Buffer', 'DRAM', 'MAC'),\n",
    ")\n",
    "\n",
    "answer(\n",
    "    question='2.1',\n",
    "    subquestion=f'How does gating impact latency in this example?',\n",
    "    answer= 'no impact',\n",
    "    required_type=('increases', 'decreases', 'no impact')\n",
    ")\n",
    "answer(\n",
    "    question='2.1',\n",
    "    subquestion=f'How does gating impact energy in this example?',\n",
    "    answer= 'decreases',\n",
    "    required_type=('increases', 'decreases', 'no impact')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ccee28",
   "metadata": {},
   "source": [
    "# Part 3: Increasing Throughput and Energy Efficiency with Skipping And Compression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9729ca",
   "metadata": {},
   "source": [
    "In this section, we will analyze how skipping affects sparse matrix multiplication. For this part, we will compress both $A$ and $B$ and perform skipping.\n",
    "\n",
    "![img](figures/skipping.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f616d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = run_timeloop_model(\n",
    "    jinja_parse_data=dict(\n",
    "        mapping='designs/untiled.map.yaml',\n",
    "        sparse_optimizations='designs/sparse_opts/buffer_skipping.yaml'\n",
    "    )\n",
    ")\n",
    "stats = open('./output_dir/timeloop-model.stats.txt', 'r').read()\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61b7efd",
   "metadata": {},
   "source": [
    "#### Question 3.1-3.2\n",
    "Interpreting Timeloop results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3a9917",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer(\n",
    "    question='3.1',\n",
    "    subquestion=f'What is the total fJ/compute without gating or skipping? If algorithmic-compute numbers are not available, use the total fJ/compute.',\n",
    "    answer= 7047.25,\n",
    "    required_type=Number\n",
    ")\n",
    "answer(\n",
    "    question='3.1',\n",
    "    subquestion=f'What is the total fJ/algorithmic-compute without gating or skipping? If algorithmic-compute numbers are not available, use the total fJ/compute.',\n",
    "    answer= 7047.25,\n",
    "    required_type=Number\n",
    ")\n",
    "answer(\n",
    "    question='3.1',\n",
    "    subquestion=f'What is the total fJ/compute with gating?',\n",
    "    answer= 31778.79,\n",
    "    required_type=Number\n",
    ")\n",
    "answer(\n",
    "    question='3.1',\n",
    "    subquestion=f'What is the total fJ/algorithmic-compute with gating?',\n",
    "    answer= 3972.35,\n",
    "    required_type=Number\n",
    ")\n",
    "answer(\n",
    "    question='3.1',\n",
    "    subquestion=f'What is the total fJ/compute with skipping and compression?',\n",
    "    answer= 15358.43,\n",
    "    required_type=Number\n",
    ")\n",
    "answer(\n",
    "    question='3.1',\n",
    "    subquestion=f'What is the total fJ/algorithmic-compute with skipping and compression?',\n",
    "    answer= 1919.80,\n",
    "    required_type=Number\n",
    ")\n",
    "answer(\n",
    "    question='3.2',\n",
    "    subquestion=f'How would increased sparsity (more zeros) impact total energy with gating and/or skipping?',\n",
    "    answer= 'decrease',\n",
    "    required_type=('increase', 'decrease', 'no impact')\n",
    ")\n",
    "answer(\n",
    "    question='3.2',\n",
    "    subquestion=f'How would increased sparsity (more zeros) impact the fJ/compute with skipping and compression?',\n",
    "    answer= 'increase',\n",
    "    required_type=('increase', 'decrease', 'no impact')\n",
    ")\n",
    "answer(\n",
    "    question='3.2',\n",
    "    subquestion=f'How would increased sparsity (more zeros) impact the fJ/algorithimic-compute with skipping and compression?',\n",
    "    answer= 'decrease',\n",
    "    required_type=('increase', 'decrease', 'no impact')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5fc771",
   "metadata": {},
   "source": [
    "#### Question 3.3 \n",
    "Below, we evaluate pJ/Algorithmic-Compute and pJ/Compute at different densities. Please complete the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f018b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "density_A, density_B, pJ_algo, pJ_actual = [], [], [], []\n",
    "\n",
    "for density_a in [0.25, 0.5, 0.75]:\n",
    "    for density_b in [0.25, 0.5, 0.75]:\n",
    "        # The designs/top.yaml.jinja2 file includes designs/arch.yaml and designs/problem.yaml by default\n",
    "        run_timeloop_model(\n",
    "            jinja_parse_data=dict(\n",
    "                mapping='designs/untiled.map.yaml',\n",
    "                sparse_optimizations='designs/sparse_opts/buffer_skipping.yaml',\n",
    "                ########################\n",
    "                #### YOUR CODE HERE ####\n",
    "                ########################\n",
    "                density_a=density_a, \n",
    "                density_b=density_b,\n",
    "            )\n",
    "        )\n",
    "        stats = open('./output_dir/timeloop-model.stats.txt', 'r').read()\n",
    "        fj_algo, fj_compute = None, None\n",
    "        found_algo, found_compute = False, False\n",
    "        for line in stats.split('\\n'):\n",
    "            if 'fJ/Algorithmic-Compute' in line:\n",
    "                found_algo = True\n",
    "            if 'fJ/Compute' in line:\n",
    "                found_compute = True\n",
    "            if found_algo and 'Total' in line and fj_algo is None:\n",
    "                fj_algo = float(line.split('=')[-1].strip())\n",
    "            if found_compute and 'Total' in line and fj_compute is None:\n",
    "                fj_compute = float(line.split('=')[-1].strip())\n",
    "        density_A.append(density_a)\n",
    "        density_B.append(density_b)\n",
    "        pJ_algo.append(fj_algo)\n",
    "        pJ_actual.append(fj_compute)\n",
    "        print(f'Density A: {density_a}, Density B: {density_b}, fJ/Algorithmic-Compute: {fj_algo}, fJ/Compute: {fj_compute}')\n",
    "        \n",
    "answer( # DO NOT CHANGE THIS BLOCK\n",
    "    question='3.3',\n",
    "    subquestion=f'What is your pJ/Algorithmic Compute? Do not change this answer block.',\n",
    "    answer=pJ_algo,\n",
    "    required_type=[Number] * len(pJ_algo)\n",
    ")\n",
    "answer( # DO NOT CHANGE THIS BLOCK\n",
    "    question='3.3',\n",
    "    subquestion=f'What is your pJ/Compute? Do not change this answer block.',\n",
    "    answer=pJ_actual,\n",
    "    required_type=[Number] * len(pJ_actual)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b3d4e4",
   "metadata": {},
   "source": [
    "Now, we will look at the interaction between densities of different tensors and the pJ per algorithmic-compute and per compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c87639",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_per_compute_df = {\n",
    "   'density_a': density_A,\n",
    "   'density_b': density_B,\n",
    "   'pJ_algorithmic': pJ_algo,\n",
    "   'pJ_actual': pJ_actual,\n",
    "}\n",
    "energy_per_compute_df = pd.DataFrame(energy_per_compute_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a7f4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(7, 3))\n",
    "ax = sns.heatmap(energy_per_compute_df.pivot(index='density_a', columns='density_b', values='pJ_algorithmic'),\n",
    "                 annot=True, ax=axes[0])\n",
    "ax.set_title('fJ/Algorithmic-Compute')\n",
    "ax.set_xlabel('B density')\n",
    "ax.set_ylabel('A density')\n",
    "ax = sns.heatmap(energy_per_compute_df.pivot(index='density_a', columns='density_b', values='pJ_actual'),\n",
    "                 annot=True, ax=axes[1])\n",
    "ax.set_title('fJ/Compute')\n",
    "ax.set_xlabel('B density')\n",
    "ax.set_ylabel('A density')\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d796240",
   "metadata": {},
   "source": [
    "# Part 4: The Effect of Sparsity on Compressed Tensor Buffer Space Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625fa0f9",
   "metadata": {},
   "source": [
    "#### Question 4.1 \n",
    "In the previous two sections we have focused on energy. In this section, we will see how different levels of sparsity affect buffer space usage when using compressed formats.\n",
    "\n",
    "Keeping the density of B constant (density=1), sweep the density of A and fill the table below. We are only interested in the usage of `Buffer` by tensor $A$. The data storage refers to \"max utilized data storage capacity\". The format storage refers to the total sum of metadata and payload for rank 1 and 0. Note that Timeloop reports the metadata cost relative to each rank, while we want to determine the total sum of non-data storage used. (Hint: look for \"max utilized data storage capacity\" and \"max utilized repr format storage capacity\" in the stats for `Buffer` and tensor $A$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bc0cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "DENSITIES_TO_RUN = [0.2, 0.4, 0.6, 0.8, 1]\n",
    "\n",
    "# The designs/top.yaml.jinja2 file includes designs/arch.yaml and designs/problem.yaml by default\n",
    "result = run_timeloop_model(\n",
    "    jinja_parse_data=dict(\n",
    "        mapping='designs/untiled.map.yaml',\n",
    "        sparse_optimizations='designs/sparse_opts/buffer_compressed.yaml',\n",
    "        density_a=1\n",
    "    )\n",
    ")\n",
    "\n",
    "stats = open('./output_dir/timeloop-model.stats.txt', 'r').read()\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96fc1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "densities = DENSITIES_TO_RUN\n",
    "########################\n",
    "#### YOUR CODE HERE ####\n",
    "########################\n",
    "data_storage_used = [13, 26, 39, 52, 64] # FILL ME\n",
    "format_storage_used = [25, 41, 49, 65, 73] # FILL ME\n",
    "\n",
    "answer( # DO NOT CHANGE THIS BLOCK\n",
    "    question='4.1',\n",
    "    subquestion=f'What is the data storage used for each density?',\n",
    "    answer=data_storage_used,\n",
    "    required_type=[int] * len(data_storage_used)\n",
    ")\n",
    "answer( # DO NOT CHANGE THIS BLOCK\n",
    "    question='4.1',\n",
    "    subquestion=f'What is the format storage used for each density?',\n",
    "    answer=format_storage_used,\n",
    "    required_type=[int] * len(format_storage_used)\n",
    ")\n",
    "\n",
    "a_capacity_df = {\n",
    "   'density': densities,\n",
    "   'data': data_storage_used,\n",
    "   'format': format_storage_used\n",
    "}\n",
    "a_capacity_df = pd.DataFrame(a_capacity_df)\n",
    "a_capacity_df['combined'] = a_capacity_df['data'] + a_capacity_df['format']\n",
    "a_capacity_df = a_capacity_df.melt('density', var_name='type', value_name='data storage used')\n",
    "sns.catplot(x='density', y='data storage used', hue='type', data=a_capacity_df, kind='point')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85547bd8",
   "metadata": {},
   "source": [
    "#### Question 4.2 \n",
    "What would be the space usage (in words) of an uncompressed representation of tensor $A$? Roughly, at what density interval would it be beneficial in terms of storage to keep $A$ in this compression format?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a329cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer(\n",
    "    question='4.2',\n",
    "    subquestion=f'What would be the space usage (in words) of an uncompressed representation of tensor A?',\n",
    "    answer= 64,\n",
    "    required_type=int,\n",
    ")\n",
    "answer(\n",
    "    question='4.2',\n",
    "    subquestion=f'Below what density would it be beneficial in terms of storage to keep A in this compression format?',\n",
    "    answer= 'FILL ME',\n",
    "    required_type=(0.2, 0.4, 0.6, 0.8, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48644eba",
   "metadata": {},
   "source": [
    "# Part 5: Breaking Assumptions\n",
    "\n",
    "For the previous sections, you were asked to assume that *all tensors are independently distributed*. While this statement tends to hold for DNNs, it is not generally true for sparse matrix multiplication. Here, we will explore how different density distributions can change the number of effectual operations and how different input densities affect the output. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fd3c93",
   "metadata": {},
   "source": [
    "#### Question 5.1 \n",
    "The Identity Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7944e457",
   "metadata": {},
   "source": [
    "In this section, both A and B are the identity matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a45373",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = K = N = 8\n",
    "\n",
    "# Example 1: Identity Pattern\n",
    "A = np.identity(K)\n",
    "B = np.identity(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109f5e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer(\n",
    "    question='5.1',\n",
    "    subquestion=f'What is the density of matrix A?',\n",
    "    answer= 0.125,\n",
    "    required_type=float\n",
    ")\n",
    "\n",
    "answer(\n",
    "    question='5.1',\n",
    "    subquestion=f'Based on independent distribution assumption, how many effectual MACs would you predict?',\n",
    "    answer= 8,\n",
    "    required_type=int\n",
    ")\n",
    "\n",
    "answer(\n",
    "    question='5.1',\n",
    "    subquestion=f'How many actual effectual MACs occur with these diagonal patterns?',\n",
    "    answer= 8,\n",
    "    required_type=int\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4571b991",
   "metadata": {},
   "source": [
    "#### Question 5.2 \n",
    "Column-Row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5695917",
   "metadata": {},
   "source": [
    "In this section, A contains a column of ones in the first column and B contains a row of ones in the first row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f450498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Column-Row Pattern\n",
    "A = np.zeros((M, K))\n",
    "B = np.zeros((K, N))\n",
    "A[:, 0] = 1  # First column all ones\n",
    "B[0, :] = 1  # First row all ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19240d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer(\n",
    "    question='5.2',\n",
    "    subquestion=f'What is the density of matrix A?',\n",
    "    answer= 0.125,\n",
    "    required_type=float\n",
    ")\n",
    "\n",
    "answer(\n",
    "    question='5.2',\n",
    "    subquestion=f'Based on independent distribution assumption, how many effectual MACs would you predict?',\n",
    "    answer= 8,\n",
    "    required_type=int\n",
    ")\n",
    "\n",
    "answer(\n",
    "    question='5.2',\n",
    "    subquestion=f'How many actual effectual MACs occur with this column-row pattern?',\n",
    "    answer= 64,\n",
    "    required_type=int\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b3a3e5",
   "metadata": {},
   "source": [
    "#### Question 5.3\n",
    "Modified Column-Row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0546ef",
   "metadata": {},
   "source": [
    "In this section, A contains a column of ones in the first column and B contains a row of ones in the last row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2174d94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3 - Modified Column-Row\n",
    "A = np.zeros((M, K))\n",
    "B = np.zeros((K, N))\n",
    "A[:,0] = 1  # First column all ones\n",
    "B[K-1,:] = 1  # Last row all ones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a221246",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer(\n",
    "    question='5.3',\n",
    "    subquestion=f'What is the density of each matrix in this pattern?',\n",
    "    answer= 0.125,\n",
    "    required_type=float\n",
    ")\n",
    "\n",
    "answer(\n",
    "    question='5.3',\n",
    "    subquestion=f'Based on independent distribution assumption, how many effectual MACs would you predict?',\n",
    "    answer= 8,\n",
    "    required_type=int\n",
    ")\n",
    "\n",
    "answer(\n",
    "    question='5.3',\n",
    "    subquestion=f'How many actual effectual MACs occur with this checkerboard pattern?',\n",
    "    answer= 0,\n",
    "    required_type=int\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad357360-e4fb-4c95-8277-42c99f3996bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
